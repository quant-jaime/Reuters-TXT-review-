{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifying newsires: a multiclass classification \n",
    "# we'll build a NN to classify Reuters newsires into 46 mutually topics\n",
    "# the problem is more single-label, multiclass classification \n",
    "# 46 different topics, each topic has atleast 10 examples in the training set \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_words = 10000, restricts the data to 10000 most frequent words in the data \n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8982 training examples\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2246 testing examples \n",
    "len(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data\n",
    "# by vectorizing the data \n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def vectorize_sequences(sequences, dimension = 10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequences in enumerate(sequences):\n",
    "        results[i, sequences] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding is widely used format for categorical data\n",
    "# also called categorical encoding\n",
    "\n",
    "def to_one_hot(labels, dimension = 46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "        return results \n",
    "    \n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternative way for categorical encoding \n",
    "\n",
    "from keras.utils.np_utils import to_categorical \n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MODEL DEFINITION\n",
    "# you want to increase dimensional space to 64 units \n",
    "# with smaller units like 16, it can drop relevant information \n",
    "# for this reason, ill use larger layers, 64 units \n",
    "\n",
    "from keras import models \n",
    "from keras import layers \n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# 3 layers in our NN\n",
    "# first, 2 layers have 64 dimensional space, and relu activation function \n",
    "# the last layer, is our output with 46 units (categories)\n",
    "# for each input sample, the network will output 1 46 -dimensional vector\n",
    "# each entry in the vector will encode a diff output class\n",
    "\n",
    "model.add(layers.Dense(64, activation = 'relu', input_shape = (10000,)))\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(46, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### COMPILING THE MODEL \n",
    "\n",
    "# best loss function is the categorical_crossentroy, which measures the distnace \n",
    "#between the two prob distributions\n",
    "# By min the distance between the two distributions, you train the network to output\n",
    "#something as close as possible to the true labels\n",
    "\n",
    "model.compile(optimizer = 'rmsprop', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### SETTING ASIDE A VALIDATION SET \n",
    "# setting aside 1,000 samples in the training data to use a validation set\n",
    "\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 151us/step - loss: 2.4721 - accuracy: 0.4971 - val_loss: 1.6810 - val_accuracy: 0.6410\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 87us/step - loss: 1.4000 - accuracy: 0.6962 - val_loss: 1.3199 - val_accuracy: 0.7150\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 86us/step - loss: 1.0683 - accuracy: 0.7635 - val_loss: 1.1394 - val_accuracy: 0.7450\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.8397 - accuracy: 0.8128 - val_loss: 1.0370 - val_accuracy: 0.7660\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.6761 - accuracy: 0.8552 - val_loss: 0.9775 - val_accuracy: 0.7900\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.5394 - accuracy: 0.8865 - val_loss: 0.9318 - val_accuracy: 0.7960\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.4319 - accuracy: 0.9113 - val_loss: 0.9153 - val_accuracy: 0.7960\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.3510 - accuracy: 0.9262 - val_loss: 0.9196 - val_accuracy: 0.8030\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.2930 - accuracy: 0.9369 - val_loss: 0.8895 - val_accuracy: 0.8180\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.2458 - accuracy: 0.9426 - val_loss: 0.9167 - val_accuracy: 0.8070\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.2129 - accuracy: 0.9468 - val_loss: 0.9714 - val_accuracy: 0.7890\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.1876 - accuracy: 0.9500 - val_loss: 0.9398 - val_accuracy: 0.8060\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.1635 - accuracy: 0.9509 - val_loss: 0.9681 - val_accuracy: 0.8040\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.1523 - accuracy: 0.9558 - val_loss: 0.9646 - val_accuracy: 0.8040\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.1429 - accuracy: 0.9550 - val_loss: 0.9750 - val_accuracy: 0.8070\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.1309 - accuracy: 0.9555 - val_loss: 0.9823 - val_accuracy: 0.8080\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.1256 - accuracy: 0.9557 - val_loss: 1.0271 - val_accuracy: 0.8080\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.1184 - accuracy: 0.9585 - val_loss: 1.0374 - val_accuracy: 0.8080\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 88us/step - loss: 0.1158 - accuracy: 0.9592 - val_loss: 1.0933 - val_accuracy: 0.7950\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.1101 - accuracy: 0.9577 - val_loss: 1.0505 - val_accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "##### TRAINING THE MODEL \n",
    "# lets define epochs to 20\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs = 20, \n",
    "                    batch_size = 512, \n",
    "                    validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7982"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partial_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### PLOTTING THE TRAINING AND VALIDATION LOSS \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label = 'Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### PLOTTING THE TRAINING AND VALIDATION ACCURACY \n",
    "\n",
    "### clears the figure \n",
    "\n",
    "a = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, a, 'bo', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label = 'Validation acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model above, seenes like the the netwrok begins to overfit after nine epochs\n",
    "# lets train a new network from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 2.6321 - accuracy: 0.5157 - val_loss: 1.7435 - val_accuracy: 0.6530\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 1.4353 - accuracy: 0.7080 - val_loss: 1.3313 - val_accuracy: 0.7040\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 1.0623 - accuracy: 0.7702 - val_loss: 1.1449 - val_accuracy: 0.7560\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.8301 - accuracy: 0.8259 - val_loss: 1.0454 - val_accuracy: 0.7780\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 91us/step - loss: 0.6513 - accuracy: 0.8609 - val_loss: 0.9664 - val_accuracy: 0.8050\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 89us/step - loss: 0.5172 - accuracy: 0.8920 - val_loss: 0.9113 - val_accuracy: 0.8130\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.4165 - accuracy: 0.9128 - val_loss: 0.8984 - val_accuracy: 0.8100\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.3326 - accuracy: 0.9310 - val_loss: 0.9146 - val_accuracy: 0.8060\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 85us/step - loss: 0.2794 - accuracy: 0.9380 - val_loss: 0.9078 - val_accuracy: 0.8120\n",
      "2246/2246 [==============================] - 0s 103us/step\n"
     ]
    }
   ],
   "source": [
    "#### RETRAINING A MODEL FROM SCRATCH \n",
    "\n",
    "#settting up the architecture of the NN\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation = 'relu', input_shape = (10000,)))\n",
    "model.add(layers.Dense(64, activation = 'relu'))\n",
    "model.add(layers.Dense(46, activation = 'softmax'))\n",
    "\n",
    "\n",
    "# defining the paramets (loss and optimizer)\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "#training the model\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train, \n",
    "          epochs = 9,\n",
    "          batch_size = 512,\n",
    "          validation_data = (x_val, y_val))\n",
    "\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9869090126543733, 0.7871772050857544]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it reaches an accuracy of nearly 80% \n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18655387355298308"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with binary classification problem, the accuracy reached by a purely randome classifier would be 50%\n",
    "# in this case, its closer to 19%\n",
    "import copy\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "float(np.sum(hits_array)) / len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GENERATING PREDICTIONS FOR NEW DATA \n",
    "## lets verify that the predict method of the model instance returns a prob distribution over\n",
    "# all 46 topics, lets generate topic predictions for all the test data\n",
    "\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.80384217e-04 5.51297271e-05 5.34924002e-05 ... 4.53110169e-06\n",
      "  3.17472109e-06 6.90075831e-05]\n",
      " [2.75524752e-03 1.74687710e-02 8.55129445e-04 ... 1.16045109e-03\n",
      "  1.13559590e-05 3.35382310e-06]\n",
      " [2.02228897e-03 7.37049222e-01 6.91833906e-03 ... 1.52662897e-03\n",
      "  2.90889846e-04 4.21143923e-04]\n",
      " ...\n",
      " [5.51811208e-05 2.67748110e-04 1.53456989e-04 ... 1.41322071e-05\n",
      "  1.12404969e-05 1.04041166e-04]\n",
      " [7.39486795e-03 1.80083126e-01 5.48448274e-03 ... 5.49850753e-04\n",
      "  4.44608042e-04 1.88416860e-03]\n",
      " [5.08833968e-04 4.98707533e-01 3.57030444e-02 ... 3.16461781e-03\n",
      "  8.71447148e-04 3.52810923e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46,)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999998"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the coefficient in the vector should sum close to 1\n",
    "np.sum(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## largest entry is the predicted class, with the highest probability \n",
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets encode the labels as integer tensor\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with integer labels, we change our loss function to sparse_categorical_crossentropy\n",
    "# still mathematically the same, just different interface \n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 161us/step - loss: 1.7309 - accuracy: 0.6429 - val_loss: 1.1805 - val_accuracy: 0.7360\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 127us/step - loss: 0.9161 - accuracy: 0.7993 - val_loss: 0.9817 - val_accuracy: 0.7680\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 123us/step - loss: 0.6046 - accuracy: 0.8672 - val_loss: 0.8696 - val_accuracy: 0.8070\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.4068 - accuracy: 0.9097 - val_loss: 0.8847 - val_accuracy: 0.8090\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.2936 - accuracy: 0.9340 - val_loss: 1.0360 - val_accuracy: 0.7790\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.2307 - accuracy: 0.9445 - val_loss: 0.9173 - val_accuracy: 0.8100\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.1935 - accuracy: 0.9501 - val_loss: 0.9071 - val_accuracy: 0.8170\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 125us/step - loss: 0.1676 - accuracy: 0.9520 - val_loss: 0.9761 - val_accuracy: 0.8140\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.1531 - accuracy: 0.9545 - val_loss: 1.0367 - val_accuracy: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0xb348f2d30>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TESING WITH 4 dimensionals on our second layer \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation = 'relu', input_shape = (10000,)))\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "model.add(layers.Dense(46, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "## training the data \n",
    "\n",
    "model.fit(partial_x_train,\n",
    "          partial_y_train,\n",
    "          epochs = 9,\n",
    "          batch_size = 128,\n",
    "          validation_data = (x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation accuracy peaks at 71%, 8% points where drop since we used a dimension less than the last layer \n",
    "## the model tried to compress alof of information into an intermediate space that is too low dimensional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### with a multiclass classification problem, the network should end with a \n",
    "# softmax activation function so that it will output a prob distribution over the N output classes\n",
    "\n",
    "# always use categorical crossentropy as the loss function. to min the distance between the pro dist\n",
    "# output by the network and the true dist of the targets\n",
    "\n",
    "# two ways to handle labels in multiclass classification\n",
    "# 1. encoding the labels via categorical encoding -one_hot_encoding\n",
    "# 2. encoding the labels as integers using sparse_categorical_crossentropy loss function\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
